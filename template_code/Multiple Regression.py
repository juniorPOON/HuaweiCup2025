import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
# --------------------------ä¸­æ–‡æ˜¾ç¤ºé…ç½®--------------------------
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']  # æŒ‡å®šæ”¯æŒä¸­æ–‡çš„å­—ä½“
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜ï¼ˆå¯é€‰ï¼Œé˜²æ­¢åç»­ç»˜å›¾è´Ÿå·å¼‚å¸¸ï¼‰

# -------------------- å¤šå…ƒçº¿æ€§å›å½’æ¨¡æ¿ --------------------
def run_multilinear_regression(x_data, y_data, future_x, feature_names=None):
    """
    å¤šå…ƒçº¿æ€§å›å½’é€šç”¨æ¨¡æ¿
    -----------------
    è¾“å…¥å‚æ•°ï¼š
        x_data: äºŒç»´ list/arrayï¼Œè‡ªå˜é‡ (æ ·æœ¬æ•° Ã— ç‰¹å¾æ•°)ï¼Œå¦‚ [[å¹¿å‘Š, å‘˜å·¥], ...]
        y_data: ä¸€ç»´ list/arrayï¼Œå› å˜é‡ï¼Œå¦‚ [120,150,...]
        future_x: äºŒç»´ list/arrayï¼Œè¦é¢„æµ‹çš„æ–°æ•°æ®ï¼Œå¦‚ [[28, 11]]
        feature_names: listï¼Œè‡ªå˜é‡åç§°ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚ ["å¹¿å‘ŠæŠ•å…¥", "å‘˜å·¥äººæ•°"]

    è¾“å‡ºï¼š
        - å›å½’ç³»æ•° & æˆªè·
        - æ¨¡å‹è¯„ä»·æŒ‡æ ‡ (RÂ², MSE)
        - æœªæ¥é¢„æµ‹ç»“æœ
        - è¿”å› model ä»¥ä¾¿å¯è§†åŒ–
    """

    # -------- 1. æ•°æ®å‡†å¤‡ --------
    X = np.array(x_data)
    y = np.array(y_data)
    future_X = np.array(future_x)

    # -------- 2. å»ºç«‹å¹¶è®­ç»ƒæ¨¡å‹ --------
    model = LinearRegression()
    model.fit(X, y)

    # -------- 3. æ¨¡å‹å‚æ•° --------
    coefs = model.coef_
    intercept = model.intercept_

    # -------- 4. æ¨¡å‹è¯„ä»· --------
    y_pred = model.predict(X)
    r2 = r2_score(y, y_pred)
    mse = mean_squared_error(y, y_pred)

    # -------- 5. æœªæ¥é¢„æµ‹ --------
    predictions = model.predict(future_X)

    # -------- 6. æ‰“å°ç»“æœ --------
    print("ğŸ“Œ æ¨¡å‹å‚æ•°ï¼š")
    if feature_names is None:
        feature_names = [f"X{i+1}" for i in range(X.shape[1])]
    for name, coef in zip(feature_names, coefs):
        print(f"  {name} çš„å›å½’ç³»æ•° = {coef:.4f}")
    print(f"  æˆªè· b = {intercept:.4f}")

    print("\nğŸ“Œ æ¨¡å‹è¯„ä»·ï¼š")
    print(f"  RÂ² = {r2:.4f}")
    print(f"  MSE = {mse:.4f}")

    print("\nğŸ“Œ é¢„æµ‹ç»“æœï¼š")
    for x_val, pred in zip(future_X, predictions):
        print(f"  X={x_val} â†’ é¢„æµ‹å€¼ {pred:.2f}")

    return model, X, y


# -------------------- å¯é€‰ç»˜å›¾å‡½æ•°ï¼ˆäºŒç»´ç‰¹å¾çš„æƒ…å†µï¼‰ --------------------
def plot_3d_regression(X, y, model, feature_names=["X1", "X2"]):
    """ ç»˜åˆ¶ 3D å›å½’å¹³é¢ï¼ˆä»…é€‚ç”¨äº 2 ä¸ªç‰¹å¾ï¼‰ """
    fig = plt.figure(figsize=(8,6))
    ax = fig.add_subplot(111, projection="3d")

    # æ•£ç‚¹å›¾ï¼ˆå®é™…æ•°æ®ï¼‰
    ax.scatter(X[:,0], X[:,1], y, color="blue", label="å®é™…æ•°æ®")

    # ç½‘æ ¼æ•°æ®
    x1_range = np.linspace(min(X[:,0]), max(X[:,0]), 10)
    x2_range = np.linspace(min(X[:,1]), max(X[:,1]), 10)
    x1_grid, x2_grid = np.meshgrid(x1_range, x2_range)
    X_grid = np.c_[x1_grid.ravel(), x2_grid.ravel()]

    # æ‹Ÿåˆå¹³é¢
    y_pred_grid = model.predict(X_grid).reshape(x1_grid.shape)
    ax.plot_surface(x1_grid, x2_grid, y_pred_grid, alpha=0.5, cmap=cm.coolwarm)

    ax.set_xlabel(feature_names[0])
    ax.set_ylabel(feature_names[1])
    ax.set_zlabel("å› å˜é‡ (Y)")
    plt.title("å¤šå…ƒçº¿æ€§å›å½’æ‹Ÿåˆå¹³é¢")
    plt.show()


# -------------------- ä½¿ç”¨æ¡ˆä¾‹ --------------------
if __name__ == "__main__":
    # å†å²æ•°æ®ï¼šå¹¿å‘ŠæŠ•å…¥ & å‘˜å·¥äººæ•° â†’ é”€å”®é¢
    X = [
        [20, 30, 15],
        [25, 35, 18],
        [30, 40, 20],
        [35, 45, 22],
        [40, 50, 25],
        [45, 55, 27]
    ]
    y = [122, 140, 153, 167, 182, 200]

    future_X = [[32, 42, 21]]

    run_multilinear_regression(X, y, future_X,
                               feature_names=["å…‰ä¼å‘ç”µé‡", "é£ç”µå‘ç”µé‡", "æ°”æ¸©"])

    # è°ƒç”¨ä½œå›¾å‡½æ•°ï¼ˆï¼ï¼ï¼ä»…é€‚ç”¨ 2 ç‰¹å¾çš„æƒ…å†µï¼Œ>=2ä¸èƒ½ç”»å›¾äº†ï¼ï¼ï¼‰
    #plot_3d_regression(X_arr, y_arr, model, feature_names=["å·¥äººæ•°é‡", "é¡¹ç›®è§„æ¨¡"])
