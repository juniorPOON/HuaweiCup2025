import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from toolbox import *
figure_set_chinese()


def run_pca_kmeans(data, n_clusters=3, n_components=2):
    """
    PCA + KMeans èšç±»å¯è§†åŒ–
    -----------------------
    data: åŸå§‹æ•°æ® (æ ·æœ¬æ•° Ã— ç‰¹å¾æ•°)
    n_clusters: èšç±»æ•°
    n_components: é™åˆ°å‡ ç»´ï¼ˆ2D æˆ– 3Dï¼‰
    """
    # 1) PCA é™ç»´
    pca = PCA(n_components=n_components)
    reduced = pca.fit_transform(data)

    # 2) KMeans èšç±»
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    labels = kmeans.fit_predict(data)

    # 3) å¯è§†åŒ–
    if n_components == 2:
        plt.figure(figsize=(8,6))
        for k in range(n_clusters):
            plt.scatter(reduced[labels==k,0], reduced[labels==k,1], label=f"ç±» {k+1}")
        plt.xlabel("ä¸»æˆåˆ†1"); plt.ylabel("ä¸»æˆåˆ†2")
        plt.title("PCAé™ç»´ + KMeansèšç±»ç»“æœ")
        plt.legend(); plt.grid(True, ls="--", alpha=0.5); plt.show()
    elif n_components == 3:
        from mpl_toolkits.mplot3d import Axes3D
        fig = plt.figure(figsize=(8,6))
        ax = fig.add_subplot(111, projection="3d")
        for k in range(n_clusters):
            ax.scatter(reduced[labels==k,0], reduced[labels==k,1], reduced[labels==k,2], label=f"ç±» {k+1}")
        ax.set_xlabel("ä¸»æˆåˆ†1"); ax.set_ylabel("ä¸»æˆåˆ†2"); ax.set_zlabel("ä¸»æˆåˆ†3")
        plt.title("PCAé™ç»´ + KMeansèšç±»ç»“æœ(3D)")
        plt.legend(); plt.show()

    # 4) è¾“å‡ºä¸»æˆåˆ†è§£é‡Šç‡
    print("ğŸ“Œ ä¸»æˆåˆ†æ–¹å·®è§£é‡Šç‡ï¼š", pca.explained_variance_ratio_)
    print(f"ç´¯è®¡è§£é‡Šç‡ = {pca.explained_variance_ratio_.sum():.3f}")

    return reduced, labels, pca


# ========== ä¸»ç¨‹åº ==========
if __name__ == "__main__":
    # æ¨¡æ‹Ÿæ•°æ® (60ä¸ªç”¨æˆ· Ã— 24å°æ—¶)
    np.random.seed(42)
    data = []
    for i in range(60):
        if i < 15:  # å·¥å‚å‹
            base = np.sin(np.linspace(0, np.pi, 24))*80 + 150
        elif i < 30:  # å•†åœºå‹
            base = np.concatenate([np.ones(12)*80, np.linspace(80,240,12)])
        elif i < 45:  # å®¶åº­å‹
            base = np.concatenate([np.ones(18)*60, np.linspace(60,200,6)])
        else:  # åŠå…¬å‹
            base = (np.sin(np.linspace(0,2*np.pi,24))*50 + 100)
        noise = np.random.normal(0,10,24)
        data.append(base + noise)
    data = np.array(data)

    # è·‘ PCA + èšç±»
    reduced, labels, pca = run_pca_kmeans(data, n_clusters=4, n_components=2)

    # æ‰“å°æ¯ç±»äººæ•°
    print("æ¯ä¸€ç±»çš„æ ·æœ¬æ•°ï¼š", np.bincount(labels))
